{
  "config": {
    "lang": [
      "en"
    ],
    "separator": "[\\s\\-]+",
    "pipeline": [
      "stopWordFilter"
    ]
  },
  "docs": [
    {
      "location": "",
      "title": "Agentic-AI",
      "text": "<p>A modular framework for building AI applications with tool integration capabilities.</p>"
    },
    {
      "location": "#overview",
      "title": "Overview",
      "text": "<p>Agentic-AI is a Python library designed to create AI-powered applications that can:</p> <ul> <li>Use multiple AI model providers (OpenAI, Anthropic, Google, Ollama)</li> <li>Dynamically discover and call tools based on user input</li> <li>Manage conversations and maintain context</li> <li>Template and version prompts with metrics tracking</li> </ul>"
    },
    {
      "location": "#key-features",
      "title": "Key Features",
      "text": "<ul> <li>Multiple Provider Support: Use models from OpenAI, Anthropic, Google, and Ollama seamlessly</li> <li>Tool Integration: Register Python functions as tools the AI can use</li> <li>Automatic Tool Discovery: AI-powered selection of relevant tools based on user queries</li> <li>Prompt Management: Create, version, and track performance of prompt templates</li> <li>Conversation Management: Maintain context across multiple interactions</li> </ul>"
    },
    {
      "location": "#installation",
      "title": "Installation",
      "text": "<pre><code># With conda\nconda env create -f environment.yml\n\n# Or with pip\npip install -r requirements.txt\n\n# For development installation\npip install -e .\n</code></pre>"
    },
    {
      "location": "#quick-start",
      "title": "Quick Start",
      "text": "<p>Check the Getting Started guide to begin using Agentic-AI.</p>"
    },
    {
      "location": "architecture/",
      "title": "Architecture",
      "text": ""
    },
    {
      "location": "architecture/#core-components",
      "title": "Core Components",
      "text": "<p>The Agentic-AI framework is built on several key components:</p>"
    },
    {
      "location": "architecture/#ai-core",
      "title": "AI Core",
      "text": "<ul> <li>AIBase: Base class implementing common functionality for all AI instances</li> <li>AI: Extension of AIBase with tool-calling capabilities</li> <li>AsyncAI: Asynchronous implementation for non-blocking operations</li> </ul>"
    },
    {
      "location": "architecture/#providers",
      "title": "Providers",
      "text": "<ul> <li>BaseProvider: Abstract base class for all model providers</li> <li>Provider Implementations: Specific implementations for OpenAI, Anthropic, Google, and Ollama</li> <li>ProviderFactory: Creates appropriate provider instances based on model ID</li> </ul>"
    },
    {
      "location": "architecture/#tool-management",
      "title": "Tool Management",
      "text": "<ul> <li>ToolManager: Central service for registering and executing tools</li> <li>AIToolFinder: Uses AI to select relevant tools based on user input</li> <li>ToolRegistry: Stores tool definitions and metadata</li> <li>ToolExecutor: Executes tools safely with proper error handling</li> </ul>"
    },
    {
      "location": "architecture/#conversation-management",
      "title": "Conversation Management",
      "text": "<ul> <li>ConversationManager: Maintains conversation history and context</li> <li>ResponseParser: Processes AI responses to extract content and thoughts</li> </ul>"
    },
    {
      "location": "architecture/#prompt-management",
      "title": "Prompt Management",
      "text": "<ul> <li>PromptManager: Manages prompt templates and versions</li> <li>PromptTemplate: Defines a parameterized prompt structure</li> <li>PromptVersion: Represents a specific version of a template</li> </ul>"
    },
    {
      "location": "architecture/#configuration",
      "title": "Configuration",
      "text": "<ul> <li>ConfigManager: Loads and provides access to configuration settings</li> <li>Model Definitions: Enumerations of supported models</li> </ul>"
    },
    {
      "location": "architecture/#component-relationships",
      "title": "Component Relationships",
      "text": "<pre><code>+-------------+     +-------------------+\n| ConfigManager|&lt;---| Provider Factory  |\n+-------------+     +-------------------+\n       |                   |\n       |                   v\n       |            +------------+\n       |            | Providers  |\n       |            +------------+\n       |                   ^\n       v                   |\n+-------------+     +------------+     +----------------+\n|  AIBase     |&lt;----| AI         |----&gt;| ToolManager   |\n+-------------+     +------------+     +----------------+\n                         |                    |\n                         v                    v\n                    +----------------+  +----------------+\n                    | ConvManager   |  | AIToolFinder  |\n                    +----------------+  +----------------+\n                         |                    |\n                         v                    v\n                    +----------------+  +----------------+\n                    | ResponseParser|  | ToolRegistry  |\n                    +----------------+  +----------------+\n                                           |\n                                           v\n                                     +----------------+\n                                     | ToolExecutor  |\n                                     +----------------+\n</code></pre>"
    },
    {
      "location": "examples/",
      "title": "Usage Examples",
      "text": "<p>This page presents practical examples of using Agentic-AI in different scenarios.</p>"
    },
    {
      "location": "examples/#basic-ai-interaction",
      "title": "Basic AI Interaction",
      "text": "<pre><code>from src.config.models import Model\nfrom src.config.config_manager import ConfigManager\nfrom src.core.tool_enabled_ai import ToolEnabledAI\nfrom src.utils.logger import LoggerFactory\n\n# Set up logger\nlogger = LoggerFactory.create()\n\n# Initialize ConfigManager\nconfig_manager = ConfigManager()\n\n# Create AI instance\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    config_manager=config_manager,\n    logger=logger\n)\n\n# Send a request\nresponse = ai.request(\"What is the capital of France?\")\nprint(response)\n</code></pre>"
    },
    {
      "location": "examples/#creating-a-weather-assistant",
      "title": "Creating a Weather Assistant",
      "text": "<pre><code>from src.config.models import Model\nfrom src.core.tool_enabled_ai import ToolEnabledAI\n\n# Create a weather assistant\nai = AI(\n    model=Model.GPT_4O,\n    system_prompt=\"You are a helpful weather assistant. Your goal is to provide weather information.\"\n)\n\n# Define weather tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"Get current weather for a location (mocked for example)\"\"\"\n    # In a real application, this would call a weather API\n    weather_data = {\n        \"New York\": \"Sunny, 75\u00b0F\",\n        \"London\": \"Rainy, 62\u00b0F\",\n        \"Tokyo\": \"Partly cloudy, 80\u00b0F\",\n        \"Paris\": \"Clear skies, 70\u00b0F\"\n    }\n    return weather_data.get(location, f\"Weather data not available for {location}\")\n\n# Register weather tool\nai.register_tool(\n    tool_name=\"get_weather\",\n    tool_function=get_weather,\n    description=\"Get current weather for a specific location\",\n    parameters_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"City or location name\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n\n# Use the weather assistant\nresponse = ai.request(\"What's the weather like in Tokyo today?\")\nprint(response)\n</code></pre>"
    },
    {
      "location": "examples/#ai-with-auto-tool-finding",
      "title": "AI with Auto Tool Finding",
      "text": "<p>This example demonstrates using <code>AIToolFinder</code> to automatically select relevant tools.</p> <pre><code>from src.config.models import Model\nfrom src.config.config_manager import ConfigManager\nfrom src.core.tool_enabled_ai import ToolEnabledAI\nfrom src.utils.logger import LoggerFactory\n\n# Set up\nlogger = LoggerFactory.create()\nconfig_manager = ConfigManager()\n\n# Create AI with auto tool finding\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    system_prompt=\"You are a helpful assistant. Use tools when appropriate to answer user queries.\",\n    config_manager=config_manager,\n    logger=logger,\n    auto_find_tools=True  # Enable auto tool finding\n)\n\n# Register multiple tools\ndef get_weather(location: str) -&gt; str:\n    \"\"\"Get the current weather for a location.\"\"\"\n    return f\"It's sunny in {location} today!\"\n\ndef calculate(expression: str) -&gt; str:\n    \"\"\"Evaluate a mathematical expression.\"\"\"\n    try:\n        result = eval(expression)\n        return f\"The result of {expression} is {result}\"\n    except:\n        return \"Sorry, I couldn't evaluate that expression.\"\n\ndef get_ticket_price(destination: str) -&gt; str:\n    \"\"\"Get ticket price for a destination.\"\"\"\n    return f\"A ticket to {destination} costs $1000 USD\"\n\n# Register all tools\nai.register_tool(\"get_weather\", get_weather, \"Get weather for a location\")\nai.register_tool(\"calculate\", calculate, \"Perform calculations\")\nai.register_tool(\"get_ticket_price\", get_ticket_price, \"Get ticket price information\")\n\n# The AI will automatically select the appropriate tool\nresponse = ai.request(\"How much does a ticket to New York cost?\")\nprint(response)\n\n# Try another query\nresponse = ai.request(\"What's 125 * 37?\")\nprint(response)\n</code></pre>"
    },
    {
      "location": "examples/#using-prompt-templates",
      "title": "Using Prompt Templates",
      "text": "<p>This example shows how to use the prompt management system.</p> <pre><code>from src.config.models import Model\nfrom src.prompts import PromptManager\nfrom src.core.tool_enabled_ai import ToolEnabledAI\n\n# Initialize prompt manager\nprompt_manager = PromptManager(storage_dir=\"data/prompts\")\n\n# Create a template for customer support\ntemplate_id = prompt_manager.create_template(\n    name=\"Customer Support\",\n    description=\"Template for answering customer support questions\",\n    template=\"You are a customer support agent for {{company}}. Answer this customer question: {{question}}\",\n    default_values={\"company\": \"Acme Corp\"}\n)\n\n# Create AI with prompt manager\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    prompt_manager=prompt_manager\n)\n\n# Use the template\nresponse = ai.request_with_template(\n    template_id=template_id,\n    variables={\n        \"question\": \"How do I reset my password?\",\n        \"company\": \"TechGiant Inc.\"\n    }\n)\nprint(response)\n\n# Create an alternative version for A/B testing\nprompt_manager.create_version(\n    template_id=template_id,\n    template_string=\"As a {{company}} support representative, please help with: {{question}}\",\n    name=\"Alternative Wording\",\n    description=\"Different wording to test effectiveness\"\n)\n\n# The A/B testing is handled automatically when user_id is provided\nresponse = ai.request_with_template(\n    template_id=template_id,\n    variables={\n        \"question\": \"How do I cancel my subscription?\",\n        \"company\": \"TechGiant Inc.\"\n    },\n    user_id=\"user-123\"  # This determines which version they get\n)\nprint(response)\n</code></pre>"
    },
    {
      "location": "getting-started/",
      "title": "Getting Started",
      "text": ""
    },
    {
      "location": "getting-started/#basic-usage",
      "title": "Basic Usage",
      "text": "<p>Here's a simple example to get started with Agentic-AI:</p> <pre><code>from src.config.models import Model\nfrom src.config.config_manager import ConfigManager\nfrom src.core.tool_enabled_ai import ToolEnabledAI\nfrom src.utils.logger import LoggerFactory\n\n# Set up logger\nlogger = LoggerFactory.create()\n\n# Initialize ConfigManager\nconfig_manager = ConfigManager()\n\n# Create AI instance\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,  # Choose your model\n    config_manager=config_manager,\n    logger=logger\n)\n\n# Send a request\nresponse = ai.request(\"What is the capital of France?\")\nprint(response)\n</code></pre>"
    },
    {
      "location": "getting-started/#adding-tool-capabilities",
      "title": "Adding Tool Capabilities",
      "text": "<p>Register tools to allow the AI to perform actions:</p> <pre><code># Create tool-enabled AI\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    config_manager=config_manager,\n    logger=logger\n)\n\n# Define a function to use as a tool\ndef get_weather(location: str) -&gt; str:\n    \"\"\"Get the weather for a location.\"\"\"\n    # In a real app, you would call a weather API here\n    return f\"It's sunny in {location} today!\"\n\n# Register the tool\nai.register_tool(\n    tool_name=\"get_weather\",\n    tool_function=get_weather,\n    description=\"Get the current weather for a location\",\n    parameters_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city or location\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n\n# The AI will now use the tool when appropriate\nresponse = ai.request(\"What's the weather like in Tokyo today?\")\nprint(response)\n</code></pre>"
    },
    {
      "location": "getting-started/#automatic-tool-finding",
      "title": "Automatic Tool Finding",
      "text": "<p>Enable the AI to automatically select relevant tools:</p> <pre><code># Create AI with auto tool finding\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    config_manager=config_manager,\n    logger=logger,\n    auto_find_tools=True  # Enable auto tool finding\n)\n\n# Register multiple tools\nai.register_tool(\"get_weather\", get_weather, \"Get weather for a location\")\nai.register_tool(\"calculate\", calculator_function, \"Perform calculations\")\n\n# The AI will automatically select the appropriate tool\nresponse = ai.request(\"What's the weather like in Paris today?\")\n</code></pre> <p>See the Tool Integration section for more details.</p>"
    },
    {
      "location": "conversations/overview/",
      "title": "Conversation Management",
      "text": ""
    },
    {
      "location": "conversations/overview/#overview",
      "title": "Overview",
      "text": "<p>The conversation management system in Agentic-AI handles:</p> <ul> <li>Maintaining conversation history</li> <li>Formatting messages for different providers</li> <li>Extracting \"thoughts\" and other metadata from responses</li> <li>Managing context and tool calls</li> </ul>"
    },
    {
      "location": "conversations/overview/#conversationmanager",
      "title": "ConversationManager",
      "text": "<p>The <code>ConversationManager</code> class tracks the conversation state:</p> <pre><code>from src.conversation.conversation_manager import ConversationManager\n\n# Create a conversation manager\nconversation = ConversationManager()\n\n# Add messages\nconversation.add_message(role=\"user\", content=\"Hello, how are you?\")\nconversation.add_message(role=\"assistant\", content=\"I'm doing well! How can I help you today?\")\n\n# Get all messages\nmessages = conversation.get_messages()\n\n# Get the latest message\nlast_message = conversation.get_last_message()\n\n# Clear the conversation\nconversation.clear()\n</code></pre>"
    },
    {
      "location": "conversations/overview/#working-with-thoughts",
      "title": "Working with Thoughts",
      "text": "<p>The system can extract AI \"thoughts\" from responses to debug reasoning:</p> <pre><code># Enable thought extraction in the conversation manager\nconversation.add_message(\n    role=\"assistant\",\n    content=\"&lt;thinking&gt;Let me consider the best approach here...&lt;/thinking&gt;The answer is 42.\",\n    extract_thoughts=True\n)\n\n# Get the processed message (without thoughts)\nprocessed_message = conversation.get_last_message()\n# Result: {\"role\": \"assistant\", \"content\": \"The answer is 42.\"}\n\n# Access the thoughts if needed\nthoughts = conversation.get_thoughts()\n# Result: [\"Let me consider the best approach here...\"]\n</code></pre>"
    },
    {
      "location": "conversations/overview/#handling-tool-calls",
      "title": "Handling Tool Calls",
      "text": "<p>Conversation manager also tracks tool calls and their results:</p> <pre><code># Add a message with tool calls\nconversation.add_message(\n    role=\"assistant\",\n    content=\"I'll check the weather for you.\",\n    tool_calls=[\n        {\n            \"name\": \"get_weather\",\n            \"arguments\": {\"location\": \"New York\"}\n        }\n    ]\n)\n\n# Add the tool response\nconversation.add_message(\n    role=\"tool\",\n    name=\"get_weather\",\n    content=\"It's sunny and 75\u00b0F in New York.\"\n)\n</code></pre>"
    },
    {
      "location": "conversations/overview/#response-parser",
      "title": "Response Parser",
      "text": "<p>The <code>ResponseParser</code> processes raw AI responses:</p> <pre><code>from src.conversation.response_parser import ResponseParser\n\nparser = ResponseParser()\n\n# Parse a response with thoughts\nresult = parser.parse_response(\n    \"&lt;thinking&gt;I should search for this information.&lt;/thinking&gt;The capital of France is Paris.\",\n    extract_thoughts=True,\n    show_thinking=False  # Hide thoughts in final output\n)\n\n# Result: {\n#   \"content\": \"The capital of France is Paris.\",\n#   \"thoughts\": \"I should search for this information.\"\n# }\n</code></pre>"
    },
    {
      "location": "conversations/overview/#sequence-diagram",
      "title": "Sequence Diagram",
      "text": "<pre><code>User     AI      ConversationManager    ResponseParser    Provider\n |       |              |                     |               |\n | Request               |                     |               |\n |------&gt;|              |                     |               |\n |       | Add user message                   |               |\n |       |-------------&gt;|                     |               |\n |       |              |                     |               |\n |       | Get messages  |                     |               |\n |       |&lt;-------------|                     |               |\n |       |              |                     |               |\n |       | Send to provider                                   |\n |       |--------------------------------------------------&gt;|\n |       |              |                     |               |\n |       | Raw response                                       |\n |       |&lt;--------------------------------------------------|\n |       |              |                     |               |\n |       | Parse response                     |               |\n |       |-----------------------------&gt;|     |               |\n |       |              |                     |               |\n |       | Parsed response                    |               |\n |       |&lt;-----------------------------|     |               |\n |       |              |                     |               |\n |       | Add assistant message              |               |\n |       |-------------&gt;|                     |               |\n |       |              |                     |               |\n | Response             |                     |               |\n |&lt;------|              |                     |               |\n</code></pre>"
    },
    {
      "location": "prompts/management/",
      "title": "Prompt Management",
      "text": ""
    },
    {
      "location": "prompts/management/#overview",
      "title": "Overview",
      "text": "<p>The prompt management system in Agentic-AI allows you to:</p> <ul> <li>Create reusable prompt templates with variables</li> <li>Version prompts to test different variations</li> <li>Track performance metrics for prompts</li> <li>A/B test different prompt versions</li> </ul>"
    },
    {
      "location": "prompts/management/#creating-templates",
      "title": "Creating Templates",
      "text": "<p>Prompt templates are parameterized prompts with placeholders for variables:</p> <pre><code>from src.prompts import PromptManager\n\n# Initialize prompt manager\nprompt_manager = PromptManager(storage_dir=\"data/prompts\")\n\n# Create a template\ntemplate_id = prompt_manager.create_template(\n    name=\"Question Template\",\n    description=\"Template for asking questions about topics\",\n    template=\"Answer this question about {{topic}}: {{question}}\",\n    default_values={\"topic\": \"general knowledge\"}\n)\n\n# Use the template with the AI\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    config_manager=config_manager,\n    prompt_manager=prompt_manager\n)\n\nresponse = ai.request_with_template(\n    template_id=template_id,\n    variables={\n        \"topic\": \"history\",\n        \"question\": \"When was the Declaration of Independence signed?\"\n    }\n)\n</code></pre>"
    },
    {
      "location": "prompts/management/#versioning-prompts",
      "title": "Versioning Prompts",
      "text": "<p>Create and test multiple versions of a prompt template:</p> <pre><code># Create an alternative version\nversion_id = prompt_manager.create_version(\n    template_id=template_id,\n    template_string=\"I need information about {{topic}}. Please answer: {{question}}\",\n    name=\"Alternative Wording\",\n    description=\"Different wording to test effectiveness\"\n)\n\n# Set a version as active\nprompt_manager.set_active_version(template_id, version_id)\n\n# Or create and set as active in one step\nversion_id = prompt_manager.create_version(\n    template_id=template_id,\n    template_string=\"New template text with {{variables}}\",\n    set_active=True\n)\n</code></pre>"
    },
    {
      "location": "prompts/management/#tracking-metrics",
      "title": "Tracking Metrics",
      "text": "<p>The prompt management system automatically tracks usage and performance metrics:</p> <pre><code># Get metrics for a template\nmetrics = prompt_manager.get_template_metrics(template_id)\n\nprint(f\"Template used {metrics['usage_count']} times\")\nfor metric_name, values in metrics[\"metrics\"].items():\n    print(f\"{metric_name}: avg={values['avg']}, min={values['min']}, max={values['max']}\")\n\n# You can also record custom metrics\nprompt_manager.record_prompt_performance(\n    usage_id=\"some-usage-id\",\n    metrics={\n        \"accuracy\": 0.95,\n        \"relevance\": 0.87\n    }\n)\n</code></pre>"
    },
    {
      "location": "prompts/management/#ab-testing",
      "title": "A/B Testing",
      "text": "<p>Perform A/B testing by providing a user ID when using templates:</p> <pre><code># Different users will get different versions based on consistent hashing\nresponse1 = ai.request_with_template(\n    template_id=template_id,\n    variables={\"key\": \"value\"},\n    user_id=\"user-123\"\n)\n\nresponse2 = ai.request_with_template(\n    template_id=template_id,\n    variables={\"key\": \"value\"},\n    user_id=\"user-456\"\n)\n\n# View metrics by version\nmetrics_by_version = prompt_manager.get_version_metrics(template_id)\nfor version_id, metrics in metrics_by_version.items():\n    print(f\"Version {version_id}: {metrics}\")\n</code></pre>"
    },
    {
      "location": "providers/overview/",
      "title": "AI Providers &amp; Models",
      "text": ""
    },
    {
      "location": "providers/overview/#supported-providers",
      "title": "Supported Providers",
      "text": "<p>Agentic-AI supports multiple AI model providers:</p> <ul> <li>Anthropic: Claude models (3.5 Haiku, 3.7 Sonnet, etc.)</li> <li>OpenAI: GPT models (4o, o3-mini, etc.)</li> <li>Google: Gemini models (2.5 Pro, 1.5 Pro, etc.)</li> <li>Ollama: Open-source models for local deployment</li> </ul> <p>Providers are supported via official SDKs.</p>"
    },
    {
      "location": "providers/overview/#models-configuration",
      "title": "Models Configuration",
      "text": "<p>Models are configured in the <code>config.yml</code> file:</p> <pre><code>models:\n  claude-3-7-sonnet:\n    name: \"Claude 3.7 Sonnet\"\n    model_id: claude-3-7-sonnet-20250219\n    provider: anthropic\n    privacy: EXTERNAL\n    quality: MAXIMUM\n    speed: STANDARD\n    parameters: 350000000000 # 350B\n    input_limit: 1000000\n    output_limit: 200000\n    temperature: 0.7\n    cost:\n      input_tokens: 3 # $3 per 1M input tokens\n      output_tokens: 15 # $15 per 1M output tokens\n      minimum_cost: 0.0001 # Minimum cost per request\n  ollama:\n    api_url: http://localhost:11434\n    # Ollama-specific settings\n</code></pre>"
    },
    {
      "location": "providers/overview/#model-selection",
      "title": "Model Selection",
      "text": "<p>Models are defined in the <code>models.py</code> file as an enumeration:</p> <pre><code>from enum import Enum\n\nclass Model(Enum):\n    # Anthropic models\n    CLAUDE_3_5_SONNET = \"claude-3-5-sonnet-20240620\"\n    CLAUDE_3_7_SONNET = \"claude-3-7-sonnet-20250219\"\n    CLAUDE_3_OPUS = \"claude-3-opus-20240229\"\n\n    # OpenAI models\n    GPT_4O = \"gpt-4o\"\n    GPT_4O_MINI = \"gpt-4o-mini\"\n    GPT_35_TURBO = \"gpt-3.5-turbo\"\n\n    # Google models\n    GEMINI_PRO = \"gemini-pro\"\n    GEMINI_2_5_PRO = \"gemini-2.5-pro\"\n\n    # Ollama models\n    LLAMA3_8B = \"llama3:8b\"\n    LLAMA3_70B = \"llama3:70b\"\n</code></pre> <p>And mapped to providers in the configuration:</p> <pre><code>models:\n  claude-3-5-sonnet-20240620:\n    provider: anthropic\n    model_id: claude-3-5-sonnet-20240620\n    ...\n  gpt-4o:\n    provider: openai\n    model_id: gpt-4o\n</code></pre>"
    },
    {
      "location": "providers/overview/#using-models",
      "title": "Using Models",
      "text": "<p>Create an AI instance with your chosen model:</p> <pre><code>from src.config.models import Model\nfrom src.core.tool_enabled_ai import ToolEnabledAI\n\n# Using an Anthropic model\nai = AI(model=Model.CLAUDE_3_7_SONNET)\n\n# Using an OpenAI model\nai = AI(model=Model.GPT_4O)\n\n# Using a Google model\nai = AI(model=Model.GEMINI_2_5_PRO)\n\n# Using an Ollama model\nai = AI(model=Model.GEMMA3-27B)\n</code></pre>"
    },
    {
      "location": "providers/overview/#model-selection-helper",
      "title": "Model Selection Helper",
      "text": "<p>The ModelSelector helps choose the appropriate model for different use cases:</p> <pre><code>from src.core.model_selector import ModelSelector, UseCase\n\n# Get a model recommendation\nrecommended_model = ModelSelector.select_model(\n    use_case=UseCase.CREATIVE_WRITING,\n    quality_preference=Quality.HIGH,\n    speed_preference=Speed.BALANCED\n)\n\n# Create AI with the recommended model\nai = AI(model=recommended_model)\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/",
      "title": "Automatic Tool Finding",
      "text": "<p>Agentic-AI includes a powerful feature called <code>AIToolFinder</code> that enables AI to automatically discover and select relevant tools based on user input.</p>"
    },
    {
      "location": "tools/auto_tool_finding/#overview",
      "title": "Overview",
      "text": "<p>The <code>AIToolFinder</code> component uses an AI model to analyze: 1. The user's request 2. Available tools and their descriptions 3. Conversation context (optional)</p> <p>Based on this analysis, it selects the most appropriate tools for handling the request.</p>"
    },
    {
      "location": "tools/auto_tool_finding/#how-it-works",
      "title": "How It Works",
      "text": ""
    },
    {
      "location": "tools/auto_tool_finding/#sequence-diagram",
      "title": "Sequence Diagram",
      "text": "<pre><code>User Query\n    |\n    v\nAIToolFinder\n    |\n    +-----&gt; Available Tools Catalog\n    |           |\n    |&lt;-----------\n    |\n    +-----&gt; Tool Selection AI Model\n    |           |\n    |&lt;-----------\n    |\n    v\nSelected Tools\n    |\n    v\nTool Executor\n    |\n    v\nFinal Response\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/#behind-the-scenes",
      "title": "Behind the Scenes",
      "text": "<ol> <li>When a user submits a query, the <code>AIToolFinder</code> prepares a prompt containing:</li> <li>The user's query</li> <li>A list of all available tools with descriptions</li> <li> <p>Optional conversation history for context</p> </li> <li> <p>This prompt is sent to a configured AI model that specializes in tool selection</p> </li> <li> <p>The AI analyzes the query and tool descriptions, then returns a JSON response listing the relevant tools:    <pre><code>{\n  \"tools\": [\"tool_name_1\", \"tool_name_2\"]\n}\n</code></pre></p> </li> <li> <p><code>AIToolFinder</code> verifies the selected tools against the available tools catalog</p> </li> <li> <p>The validated list of tool names is returned to the calling component (usually <code>ToolManager</code>)</p> </li> </ol>"
    },
    {
      "location": "tools/auto_tool_finding/#implementation",
      "title": "Implementation",
      "text": "<p>The core of <code>AIToolFinder</code> is in <code>src/tools/ai_tool_finder.py</code>:</p> <pre><code>class AIToolFinder:\n    \"\"\"\n    Uses an AI model to find relevant tools based on user prompts and tool descriptions.\n    \"\"\"\n\n    def __init__(self,\n                 model_id: str,\n                 config_manager: ConfigManager,\n                 logger: LoggerInterface):\n        \"\"\"\n        Initialize the AIToolFinder.\n\n        Args:\n            model_id: The ID of the AI model to use for tool finding.\n            config_manager: Configuration manager instance.\n            logger: Logger instance.\n        \"\"\"\n        # ... initialization ...\n\n    def find_tools(self, user_prompt: str, conversation_history: Optional[List[str]] = None) -&gt; Set[str]:\n        \"\"\"\n        Analyzes the user's prompt and returns a set of relevant tool names.\n        \"\"\"\n        # ... implementation ...\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/#usage",
      "title": "Usage",
      "text": ""
    },
    {
      "location": "tools/auto_tool_finding/#enabling-auto-tool-finding",
      "title": "Enabling Auto Tool Finding",
      "text": "<p>Enable automatic tool finding by setting <code>auto_find_tools=True</code> when creating an AI instance:</p> <pre><code>from src.core.tool_enabled_ai import ToolEnabledAI\nfrom src.config.models import Model\n\n# Create AI with auto tool finding\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    auto_find_tools=True\n)\n\n# Register tools\nai.register_tool(\"tool1\", tool1_function, \"Tool 1 description\")\nai.register_tool(\"tool2\", tool2_function, \"Tool 2 description\")\n\n# When user requests come in, AIToolFinder will automatically select tools\nresponse = ai.request(\"Can you tell me the weather in New York?\")\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/#manual-tool-finding-via-toolmanager",
      "title": "Manual Tool Finding via ToolManager",
      "text": "<p>You can also use the <code>ToolManager</code> directly:</p> <pre><code>from src.tools.tool_manager import ToolManager\nfrom src.config.models import Model\n\n# Create tool manager with auto tool finding\ntool_manager = ToolManager(\n    config_manager=config_manager,\n    logger=logger\n)\n\n# Enable auto tool finding with a specific model\ntool_manager.enable_auto_tool_finding(\n    enabled=True,\n    tool_finder_model_id=Model.GPT_4O_MINI\n)\n\n# Register tools\ntool_manager.register_tool(\"tool1\", tool1_function, \"Tool 1 description\")\ntool_manager.register_tool(\"tool2\", tool2_function, \"Tool 2 description\")\n\n# Find and execute tools for a user prompt\nresults = tool_manager.process_with_tools(\"What's the weather like today?\")\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/#customizing-the-tool-finding-model",
      "title": "Customizing the Tool Finding Model",
      "text": "<p>You can specify which AI model should be used for tool finding:</p> <pre><code>from src.tools.tool_manager import ToolManager\nfrom src.config.models import Model\n\n# Create tool manager\ntool_manager = ToolManager()\n\n# Enable auto tool finding with a specific model\ntool_manager.enable_auto_tool_finding(\n    enabled=True,\n    tool_finder_model_id=Model.GPT_4O_MINI  # Choose a smaller/faster model for tool finding\n)\n</code></pre>"
    },
    {
      "location": "tools/auto_tool_finding/#best-practices",
      "title": "Best Practices",
      "text": "<ol> <li>Tool Descriptions: Provide clear, concise descriptions for each tool</li> <li>Tool Naming: Use descriptive names that indicate the tool's function</li> <li>Model Selection: For tool finding, smaller/faster models are often sufficient</li> <li>Performance Monitoring: Track which tools are selected and adjust descriptions if tools are being incorrectly selected</li> <li>Conversation Context: Include conversation history when relevant to provide better context for tool selection</li> </ol>"
    },
    {
      "location": "tools/overview/",
      "title": "Tool Integration",
      "text": ""
    },
    {
      "location": "tools/overview/#overview",
      "title": "Overview",
      "text": "<p>Tools allow the AI to perform actions and retrieve information beyond its training data. The Agentic-AI framework includes a sophisticated tool management system that enables:</p> <ol> <li>Registering Python functions as tools</li> <li>Automatic discovery of relevant tools for user requests</li> <li>Systematic execution of tool calls with proper error handling</li> </ol>"
    },
    {
      "location": "tools/overview/#tool-components",
      "title": "Tool Components",
      "text": "<ul> <li>ToolManager: Central service that coordinates all tool operations</li> <li>AIToolFinder: AI-powered component that selects relevant tools based on user input</li> <li>ToolRegistry: Stores tool definitions and makes them available to the AI</li> <li>ToolExecutor: Executes tool calls safely with error handling</li> <li>ToolPromptBuilder: Constructs appropriate prompts for tool usage</li> </ul>"
    },
    {
      "location": "tools/overview/#creating-and-registering-tools",
      "title": "Creating and Registering Tools",
      "text": "<p>Tools are Python functions that can be registered with the AI. Each tool needs:</p> <ul> <li>A unique name</li> <li>The function implementing the tool's logic</li> <li>A description of what the tool does</li> <li>A schema defining the parameters the tool accepts</li> </ul> <pre><code>def get_weather(location: str) -&gt; str:\n    \"\"\"Get the current weather for a location.\"\"\"\n    # Implementation\n    return f\"Weather data for {location}\"\n\nai.register_tool(\n    tool_name=\"get_weather\",\n    tool_function=get_weather,\n    description=\"Get current weather for a location\",\n    parameters_schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city or location\"\n            }\n        },\n        \"required\": [\"location\"]\n    }\n)\n</code></pre>"
    },
    {
      "location": "tools/overview/#automatic-tool-finding",
      "title": "Automatic Tool Finding",
      "text": "<p>The AIToolFinder component uses an AI model to determine which tools are relevant for a given user query:</p> <pre><code># Enable auto tool finding when creating the AI\nai = AI(\n    model=Model.CLAUDE_3_7_SONNET,\n    config_manager=config_manager,\n    logger=logger,\n    auto_find_tools=True\n)\n\n# Register multiple tools\nai.register_tool(\"get_weather\", get_weather, \"Get weather information\")\nai.register_tool(\"calculate\", calculator, \"Perform calculations\")\nai.register_tool(\"search_web\", search_web, \"Search the web for information\")\n\n# The AI will automatically select the appropriate tool\nresponse = ai.request(\"What's the weather like in Paris?\")\n</code></pre>"
    },
    {
      "location": "tools/overview/#tool-selection-sequence",
      "title": "Tool Selection Sequence",
      "text": "<pre><code>User Request\n     |\n     v\nAI (Tool-Enabled)\n     |\n     v\nTool Manager ---&gt; Available Tools\n     |              |\n     v              |\nAIToolFinder &lt;------+\n     |\n     v\nSelected Tools\n     |\n     v\nTool Executor\n     |\n     v\nTool Results\n     |\n     v\nFinal AI Response\n</code></pre>"
    },
    {
      "location": "tools/overview/#creating-custom-tool-strategies",
      "title": "Creating Custom Tool Strategies",
      "text": "<p>You can create custom tool selection strategies by implementing the <code>ToolStrategy</code> interface:</p> <pre><code>from src.tools.interfaces import ToolStrategy\n\nclass CustomToolStrategy(ToolStrategy):\n    def select_tools(self, user_prompt, available_tools, context=None):\n        # Your custom logic to select tools\n        selected_tools = []\n        # ...\n        return selected_tools\n\n# Use your custom strategy\ntool_manager.set_tool_strategy(CustomToolStrategy())\n</code></pre>"
    }
  ]
}